{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def45360-f674-4c36-8c2c-1c1fb9f7965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_folder = os.path.dirname(os.path.abspath('__file__'))\n",
    "parent_folder = os.path.dirname(current_folder)\n",
    "grandparent_folder = os.path.dirname(parent_folder)\n",
    "grandgrandparent_folder = os.path.dirname(grandparent_folder)\n",
    "sys.path.append(grandgrandparent_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25383d53-9203-44a4-8b87-bf002ea1288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import copy\n",
    "\n",
    "from methods.MLP import MLP\n",
    "from methods.methodsDataset.MLPDataset import MLPDataset\n",
    "from methods.DataDrivenMethods import DDMethod\n",
    "from solvers.Solver import Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d2af12a-bbb6-4639-aca5-398a6c3b3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_solver = {'equation': 'Poisson', 'domain': [0., 1.], 'D': 1., 'nx': 101}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "params_MLP = {'layer_dims': None, 'activations': None, 'device': device, 'seed': 123}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b85eba0-e667-4ab7-baa5-11400c272a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dmin, Dmax = 0.1, 10\n",
    "D_list = np.linspace(Dmin, Dmax, 1000)\n",
    "\n",
    "U_sols = []\n",
    "solver = Solver(params={'solver': params_solver})\n",
    "for d in D_list:\n",
    "    solver.change_D(new_D=d)\n",
    "    U_sols.append(solver.solve())\n",
    "\n",
    "U_sols = np.stack(U_sols)\n",
    "D = torch.Tensor(D_list).view(-1, 1).to(device)\n",
    "U = torch.Tensor(U_sols).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "012807db-7d7a-4990-9f49-d9cfe77b9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_train, D_test, U_train, U_test = sklearn.model_selection.train_test_split(D, U,test_size=0.2, random_state=params_MLP['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "474d49a0-6bea-4502-b5f3-59bea8c2335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    return D_train, D_test, U_train, U_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6b993f9-cd86-4d12-922f-4eec7fc94725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(x, y = 0):\n",
    "    return torch.square(y - x).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a78ed795-0daf-4689-890d-8f5cc74da211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial, input_size, output_size):\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 10)\n",
    "    layers = [input_size]\n",
    "    activations = []\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"units_l{}\".format(i), 52, 512)\n",
    "        activation = trial.suggest_categorical(\"activation_l{}\".format(i), [\"tanh\", \"softplus\", \"relu\"])\n",
    "        layers += [out_features]\n",
    "        activations.append(activation)\n",
    "    layers += [output_size]\n",
    "    params_MLP_trial = copy.deepcopy(params_MLP)\n",
    "    params_MLP_trial['layer_dims'] = layers\n",
    "    params_MLP_trial['activations'] = activations\n",
    "    return MLP(params={'solver':None, 'method':params_MLP_trial})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26daf0bc-d997-407d-842e-98700cfaff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model = define_model(trial, 1, 101)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    \n",
    "    D_train, D_val, U_train, U_val = get_dataset()\n",
    "\n",
    "    trainDataset = MLPDataset(x=D_train, y=U_train)\n",
    "    valDataset = MLPDataset(x=D_val, y=U_val)\n",
    "\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 32, 256)\n",
    "    torch.manual_seed(params_MLP['seed'])\n",
    "    trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size=batch_size, shuffle=True)\n",
    "    valLoader = torch.utils.data.DataLoader(valDataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Training of the model.\n",
    "    loss_vals = []\n",
    "    for epoch in range(1000):\n",
    "        model.train()\n",
    "        for i, data in enumerate(trainLoader):\n",
    "            inputs, label = data\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        loss_val = 0.\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(valLoader):\n",
    "                inputs, label = data\n",
    "                optimizer.zero_grad()\n",
    "                output = model(inputs)\n",
    "                loss_val += loss_fn(output, label).item()\n",
    "        loss_val /= (i+1)\n",
    "        loss_vals.append(loss_val)\n",
    "\n",
    "        trial.report(min(loss_vals), epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return min(loss_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cd87a54-d252-4a6e-be68-716555ed1845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-01 16:15:36,039] A new study created in memory with name: no-name-1d625898-a44d-4df8-8063-35c0bedbca63\n"
     ]
    }
   ],
   "source": [
    "sampler = TPESampler(seed=params_MLP['seed'])\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7c221c-438c-44a0-b5c2-5772892fe31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=10, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a2edad-074d-47e1-83be-a963dfd84a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14791500-59c8-4a11-b468-47ca5369e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = []\n",
    "layer_dims = []\n",
    "\n",
    "for key, value in trial.params.items():\n",
    "    if key.split('_')[0] == 'activation':\n",
    "        activations.append(value)\n",
    "    elif key.split('_')[0] == 'units':\n",
    "        layer_dims.append(value)\n",
    "    elif key == 'optimizer':\n",
    "        optimizer = value\n",
    "    elif key == 'lr':\n",
    "        lr = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6101b79c-43b3-44a6-b42a-8a0827585b54",
   "metadata": {},
   "source": [
    "Use this to fill config_step_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c794c9-5dbb-4ef3-9f68-ca238d67fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(activations, '\\n', layer_dims, '\\n', optimizer, '\\n', lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0cebce-6df1-44cc-aa1e-51e3834853ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CEMRACS_SciML",
   "language": "python",
   "name": "cemracs_sciml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
