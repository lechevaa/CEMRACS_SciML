{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59840aa6-4237-4ec7-b9d0-2f7e0717c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_folder = os.path.dirname(os.path.abspath('__file__'))\n",
    "parent_folder = os.path.dirname(current_folder)\n",
    "grandparent_folder = os.path.dirname(parent_folder)\n",
    "grandgrandparent_folder = os.path.dirname(grandparent_folder)\n",
    "grandgrandgrandparent_folder = os.path.dirname(grandgrandparent_folder)\n",
    "sys.path.append(grandgrandgrandparent_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a875318b-657c-4a8b-90dc-adfcc468952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import copy\n",
    "\n",
    "from methods.DeepONet import DeepONet\n",
    "from methods.methodsDataset.DeepONetDataset import DeepONetDataset\n",
    "from methods.DataDrivenMethods import DDMethod\n",
    "from solvers.Solver import Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6b5c8b-5400-4cbb-a066-039bc2ec398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_solver = {'equation': 'Poisson', 'domain': [0., 1.], 'D': 0., 'nx': 101}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "params_DONUT ={\n",
    "             'branch': {'layer_dims': None, 'activations': None, 'device': 'cpu', 'seed': 123}, \n",
    "             'trunk':{'layer_dims': None, 'activations': None, 'device': 'cpu', 'seed': 123}\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b811aabe-8cce-4f63-b4a1-36c3f0db7b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dmin, Dmax = 0.1, 10\n",
    "D_list = np.linspace(Dmin, Dmax, 1000)\n",
    "\n",
    "U_sols = []\n",
    "solver = Solver(params={'solver': params_solver})\n",
    "for d in D_list:\n",
    "    solver.change_D(new_D=d)\n",
    "    U_sols.append(solver.solve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bd35107-55e2-407b-afbb-08a24132a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train, d_val, u_train, u_val = sklearn.model_selection.train_test_split(D_list, U_sols, test_size=0.2, \n",
    "                                                                          random_state=params_DONUT['branch']['seed'])\n",
    "\n",
    "D_train_repeated = torch.Tensor([[d] * len(solver.x) for d in d_train]).view(-1, 1)\n",
    "D_val_repeated = torch.Tensor([[d] * len(solver.x) for d in d_val]).view(-1, 1)\n",
    "x = torch.Tensor(solver.x).view(-1, 1)\n",
    "X_train = x.repeat(d_train.shape[0], 1)\n",
    "X_val = x.repeat(d_val.shape[0], 1)\n",
    "\n",
    "DX_train = torch.cat((D_train_repeated, X_train), dim=1)\n",
    "DX_val = torch.cat((D_val_repeated, X_val), dim=1)\n",
    "dU_train = torch.Tensor(np.array(u_train)).flatten()\n",
    "dU_val = torch.Tensor(np.array(u_val)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fe1c06b-dee8-4172-abd0-f3252f69ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    return DX_train, DX_val, dU_train, dU_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee124e3c-f2ae-479f-84fc-75096fcb19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(x, y = 0):\n",
    "    return torch.square(y - x).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a665e711-a0b5-4aef-abd5-41a871b09bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial, input_size, output_size):\n",
    "    n_layers_branch = trial.suggest_int(\"n_layers_branch\", 1, 5)\n",
    "    branch_layers = [input_size]\n",
    "    branch_activations = []\n",
    "    \n",
    "    for i in range(n_layers_branch):\n",
    "        out_features = trial.suggest_int(\"branch_units_l{}\".format(i), 52, 512)\n",
    "        activation = trial.suggest_categorical(\"branch_activation_l{}\".format(i), [\"tanh\", \"softplus\", \"relu\"])\n",
    "        branch_layers += [out_features]\n",
    "        branch_activations.append(activation)\n",
    "    branch_layers += [output_size]\n",
    "\n",
    "    n_layers_trunk = trial.suggest_int(\"n_layers_trunk\", 1, 5)\n",
    "    trunk_layers = [input_size]\n",
    "    trunk_activations = []\n",
    "    for i in range(n_layers_trunk):\n",
    "        out_features = trial.suggest_int(\"trunk_units_l{}\".format(i), 52, 512)\n",
    "        activation = trial.suggest_categorical(\"trunk_activation_l{}\".format(i), [\"tanh\", \"softplus\", \"relu\"])\n",
    "        trunk_layers += [out_features]\n",
    "        trunk_activations.append(activation)\n",
    "    trunk_layers += [output_size]\n",
    "    \n",
    "    params_DONUT_trial = copy.deepcopy(params_DONUT)\n",
    "    params_DONUT_trial['branch']['layer_dims'] = branch_layers\n",
    "    params_DONUT_trial['branch']['activations'] = branch_activations\n",
    "    params_DONUT_trial['trunk']['layer_dims'] = trunk_layers\n",
    "    params_DONUT_trial['trunk']['activations'] = trunk_activations\n",
    " \n",
    "    return DeepONet(params={'solver':None, 'method':params_DONUT_trial})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "011b3b46-1c09-4cf7-95cd-2117ec7f220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    basis_number = trial.suggest_int(\"basis_number\", 1, 25)\n",
    "    model = define_model(trial, 1, basis_number)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    \n",
    "    D_train, D_val, U_train, U_val = get_dataset()\n",
    "\n",
    "    trainDataset = DeepONetDataset(x=D_train, y=U_train)\n",
    "    valDataset = DeepONetDataset(x=D_val, y=U_val)\n",
    "\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 512, 2048)\n",
    "    torch.manual_seed(params_DONUT['branch']['seed'])\n",
    "    trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size=batch_size, shuffle=True)\n",
    "    valLoader = torch.utils.data.DataLoader(valDataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Training of the model.\n",
    "    loss_vals = []\n",
    "    for epoch in range(1000):\n",
    "        model.train()\n",
    "        for i, data in enumerate(trainLoader):\n",
    "            inputs, label = data\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs[:, 0:1], inputs[:, 1:2])\n",
    "            loss = loss_fn(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        loss_val = 0.\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(valLoader):\n",
    "                inputs, label = data\n",
    "                optimizer.zero_grad()\n",
    "                output = model(inputs[:, 0:1], inputs[:, 1:2])\n",
    "                loss_val += loss_fn(output, label).item()\n",
    "        loss_val /= (i+1)\n",
    "        loss_vals.append(loss_val)\n",
    "\n",
    "        trial.report(min(loss_vals), epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return min(loss_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6f1286b-335c-47d8-b6c9-ce1aa48e50c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-01 17:01:40,467] A new study created in memory with name: no-name-4c65dfee-264f-4d51-9d50-c835e491174c\n"
     ]
    }
   ],
   "source": [
    "sampler = TPESampler(seed=params_DONUT['branch']['seed'])\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd5698-0efd-4559-a251-3d992fbecbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=10, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa9f34e-b1ed-40ed-aeb9-8cb2083bbd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb6d65-5ed9-4e01-90e6-f2ecaccca437",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_activations = []\n",
    "branch_layer_dims = []\n",
    "\n",
    "trunk_activations = []\n",
    "trunk_layer_dims = []\n",
    "\n",
    "for key, value in trial.params.items():\n",
    "    if key.split('_')[0] == 'branch':\n",
    "        if key.split('_')[1] == 'activation':\n",
    "            branch_activations.append(value)\n",
    "        elif key.split('_')[1] == 'units':\n",
    "            branch_layer_dims.append(value)\n",
    "        \n",
    "    elif key.split('_')[0] == 'trunk':\n",
    "        if key.split('_')[1] == 'activation':\n",
    "            trunk_activations.append(value)\n",
    "        elif key.split('_')[1] == 'units':\n",
    "            trunk_layer_dims.append(value)\n",
    "    elif key == 'optimizer':\n",
    "        optimizer = value\n",
    "    elif key == 'lr':\n",
    "        lr = value\n",
    "    elif key == 'batch_size':\n",
    "        batch_size = value\n",
    "    elif key == 'basis_number':\n",
    "        basis_number = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ff173-7afa-4366-a795-2c3ad64b66fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('branch:\\n', branch_activations, '\\n', branch_layer_dims, \n",
    "      '\\ntrunk:\\n', trunk_activations, '\\n', trunk_layer_dims,\n",
    "      '\\nhyperparameters\\n',\n",
    "      optimizer, '\\n', lr, '\\n', batch_size, '\\n', basis_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c05b9-94b7-4b4f-902d-60dcbbb763a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CEMRACS_SciML",
   "language": "python",
   "name": "cemracs_sciml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
